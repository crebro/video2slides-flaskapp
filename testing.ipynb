{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c96349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "import os\n",
    "import subprocess\n",
    "import img2pdf\n",
    "import re\n",
    "import cv2\n",
    "import random\n",
    "from datetime import timedelta\n",
    "import shutil\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_socketio import SocketIO, emit\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0630124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_string(length=8):\n",
    "    \"\"\"\n",
    "    Generate a random string of fixed length.\n",
    "    \n",
    "    Args:\n",
    "        length (int): Length of the random string\n",
    "    \n",
    "    Returns:\n",
    "        str: Random string\n",
    "    \"\"\"\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "    return ''.join(random.choice(letters) for i in range(length))\n",
    "\n",
    "def extract_youtube_id(url):\n",
    "    \"\"\"\n",
    "    Extract the YouTube video ID from a URL.\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*',\n",
    "        r'(?:embed\\/|v\\/|shorts\\/)([0-9A-Za-z_-]{11})',\n",
    "        r'(?:youtu\\.be\\/)([0-9A-Za-z_-]{11})'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "def get_subtitles(video_id):\n",
    "    \"\"\"\n",
    "    Extract subtitles from a YouTube video link using yt-dlp.\n",
    "    Returns the path to the subtitle file (.srt) if successful, else None.\n",
    "    \"\"\"\n",
    "\n",
    "    ytt_api = YouTubeTranscriptApi()\n",
    "    fetched_transcript = ytt_api.fetch(video_id)\n",
    "\n",
    "    return fetched_transcript\n",
    "\n",
    "def images_to_pdf(input_folder, output_pdf):\n",
    "    \"\"\"\n",
    "    Convert all images in a folder to a single PDF file using img2pdf.\n",
    "    \"\"\"\n",
    "    image_files = []\n",
    "    for f in os.listdir(input_folder):\n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
    "            image_files.append(os.path.join(input_folder, f))\n",
    "    \n",
    "    image_files.sort(key=lambda x: [int(c) if c.isdigit() else c for c in re.split('([0-9]+)', x)])\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found in the directory\")\n",
    "        return\n",
    "    \n",
    "    with open(output_pdf, \"wb\") as f:\n",
    "        f.write(img2pdf.convert(image_files))\n",
    "    \n",
    "    print(f\"Successfully created {output_pdf} with {len(image_files)} images\")\n",
    "\n",
    "def compare_frames(frame1, frame2):\n",
    "    \"\"\"\n",
    "    Compare two frames and return their similarity score (0-1).\n",
    "    \"\"\"\n",
    "    if frame1.shape != frame2.shape:\n",
    "        return 0.0\n",
    "    \n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    (score, _) = compare_ssim(gray1, gray2, full=True)\n",
    "    return score\n",
    "\n",
    "STATIC_FOLDER = \"./static/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76db4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_frames_task(video_path, socket_id=None, interval_seconds=10, similarity_threshold=0.95, server_video_id=None):\n",
    "    \"\"\"\n",
    "    Background task to extract frames and generate PDF.\n",
    "    \"\"\"\n",
    "    video_id = extract_youtube_id(video_path)\n",
    "\n",
    "    video_identification_on_disk = server_video_id if server_video_id else generate_random_string()\n",
    "    output_dir = os.path.join(STATIC_FOLDER, video_identification_on_disk)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    video_dir = os.path.join(STATIC_FOLDER, 'videos')\n",
    "    video_full_path = os.path.join(video_dir, f'{video_id}.mp4')\n",
    "    \n",
    "    # Download video if it doesn't exist\n",
    "    if not os.path.exists(video_full_path):\n",
    "        print(f\"Downloading video {video_id}...\")\n",
    "        cmd = [\n",
    "            'yt-dlp', '-f', 'bestvideo[ext=mp4]',\n",
    "            '--merge-output-format', 'mp4',\n",
    "            '--output', video_full_path,\n",
    "            video_path\n",
    "        ]\n",
    "        subprocess.run(cmd, stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    # Temporary directory for extracted frames\n",
    "    temp_dir = os.path.join(output_dir, \"temp_frames\")\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    # Get video duration\n",
    "    try:\n",
    "        cmd = [\n",
    "            'ffprobe', '-v', 'error', '-show_entries', \n",
    "            'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1', \n",
    "            video_full_path\n",
    "        ]\n",
    "        duration = float(subprocess.check_output(cmd).decode('utf-8').strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting duration: {e}\")\n",
    "        duration = 0\n",
    "    \n",
    "    print(f\"Video duration: {timedelta(seconds=duration)}\")\n",
    "    \n",
    "    # Extract frames at intervals using FFmpeg\n",
    "    frame_pattern = os.path.join(temp_dir, \"frame_%04d.png\")\n",
    "    cmd = [\n",
    "        'ffmpeg', '-y', '-i', video_full_path, '-vf', \n",
    "        f'fps=1/{interval_seconds}', '-vsync', 'vfr', \n",
    "        frame_pattern\n",
    "    ]\n",
    "    subprocess.run(cmd, stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    frame_files = sorted([f for f in os.listdir(temp_dir) if f.startswith('frame_')])\n",
    "    \n",
    "    unique_frame_count = 0\n",
    "    unique_frame_timestamps = []\n",
    "    paths_collection = []\n",
    "\n",
    "    # We'll track the previous frame in the sequence and write the previous\n",
    "    # frame when we detect a change â€“ that ensures we save the final frame of\n",
    "    # a repeated slide (end of the run) rather than the first frame.\n",
    "    prev_frame = None\n",
    "    prev_timestamp = None\n",
    "\n",
    "    for i, frame_file in enumerate(frame_files, 1):\n",
    "        frame_path = os.path.join(temp_dir, frame_file)\n",
    "        current_frame = cv2.imread(frame_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if current_frame is None:\n",
    "            continue\n",
    "\n",
    "        # this is technically not true, but this allows us to process the subtitles easily\n",
    "        timestamp = (i - 1) * interval_seconds\n",
    "\n",
    "        if prev_frame is None:\n",
    "            # first frame of the video (start a run)\n",
    "            prev_frame = current_frame.copy()\n",
    "            prev_timestamp = timestamp\n",
    "            continue\n",
    "\n",
    "        # compare current frame with the previous frame to detect a boundary\n",
    "        similarity = compare_frames(current_frame, prev_frame)\n",
    "        if similarity < similarity_threshold:\n",
    "            # boundary detected: save the previous frame (end of the previous run)\n",
    "            unique_frame_count += 1\n",
    "            output_path = os.path.join(output_dir, f\"frame_{unique_frame_count}.png\")\n",
    "            cv2.imwrite(output_path, prev_frame)\n",
    "            unique_frame_timestamps.append(prev_timestamp)\n",
    "            paths_collection.append(output_path)\n",
    "\n",
    "        # advance previous to current for next iteration\n",
    "        prev_frame = current_frame.copy()\n",
    "        prev_timestamp = timestamp\n",
    "\n",
    "    # After iterating, save the last run's final frame (if any)\n",
    "    if prev_frame is not None:\n",
    "        unique_frame_count += 1\n",
    "        output_path = os.path.join(output_dir, f\"frame_{unique_frame_count}.png\")\n",
    "        cv2.imwrite(output_path, prev_frame)\n",
    "        unique_frame_timestamps.append(prev_timestamp)\n",
    "        paths_collection.append(output_path)\n",
    "\n",
    "    shutil.rmtree(temp_dir)\n",
    "    images_to_pdf(output_dir, os.path.join(output_dir, \"output.pdf\"))\n",
    "\n",
    "    # Group subtitles by unique frame timestamps\n",
    "    print(unique_frame_timestamps)\n",
    "    subtitle_groups = []\n",
    "\n",
    "    try:\n",
    "        subtitles = get_subtitles(video_id)\n",
    "        \n",
    "        for idx, ts in enumerate(unique_frame_timestamps):\n",
    "            next_ts = unique_frame_timestamps[idx + 1] if idx + 1 < len(unique_frame_timestamps) else float('inf')\n",
    "            \n",
    "            group = {\n",
    "                \"frame_index\": idx + 1,\n",
    "                \"timestamp\": ts,\n",
    "                \"subtitles\": []\n",
    "            }\n",
    "            \n",
    "            for sub in subtitles:\n",
    "                if ts <= sub.start < next_ts:\n",
    "                    group['subtitles'].append(sub.text)\n",
    "            \n",
    "            subtitle_groups.append(group)\n",
    "            \n",
    "        # Save to JSON file\n",
    "        json_path = os.path.join(output_dir, \"subtitle_groups.json\")\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(subtitle_groups, f, indent=4, ensure_ascii=False)\n",
    "            print(f\"Successfully written to JSON file\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing subtitles: {e}\")\n",
    "\n",
    "    print(f\"Finished processing {video_id}. Found {unique_frame_count} unique frames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62c9a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video duration: 0:12:51.160000\n",
      "None\n",
      "Successfully created ./static/AUQnnoFd/output.pdf with 8 images\n",
      "[90, 120, 240, 310, 450, 590, 600, 760]\n",
      "Successfully written to JSON file\n",
      "Finished processing q1eor6oIuUo. Found 8 unique frames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "extract_frames_task(video_path=\"https://www.youtube.com/watch?v=q1eor6oIuUo\", socket_id=None, interval_seconds=10, similarity_threshold=0.95, server_video_id=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
